import streamlit as st
import numpy as np
import pandas as pd
import io
import json
import time
import requests
import re
import zipfile
from datetime import datetime
from typing import List, Dict, Tuple, Optional
import hashlib

# Simple password - no secrets file needed to avoid configuration issues
CORRECT_PASSWORD = "neurocrix2024"

# Password protection
def check_password():
    """Returns True if the user had the correct password."""
    
    def password_entered():
        """Checks whether a password entered by the user is correct."""
        if st.session_state["password"] == CORRECT_PASSWORD:
            st.session_state["password_correct"] = True
            del st.session_state["password"]  # don't store password
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        # First run, show input for password
        st.text_input(
            "ðŸ” Enter Password to Access EEG Platform", 
            type="password", 
            on_change=password_entered, 
            key="password"
        )
        st.write("*Contact administrator for access credentials*")
        return False
    elif not st.session_state["password_correct"]:
        # Password not correct, show input + error
        st.text_input(
            "ðŸ” Enter Password to Access EEG Platform", 
            type="password", 
            on_change=password_entered, 
            key="password"
        )
        st.error("ðŸ˜ž Password incorrect. Please try again.")
        return False
    else:
        # Password correct
        return True

# Optional imports with fallbacks
try:
    import scipy.signal as sp_signal
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False

# Database Configuration with REAL Bonn URLs
PUBLIC_DATABASES = {
    "bonn_seizure": {
        "name": "Bonn University Seizure Database",
        "base_url": "https://www.ukbonn.de/epileptologie/arbeitsgruppen/ag-lehnertz/downloads/",
        "description": "Real EEG recordings - healthy subjects and seizure patients",
        "format": "txt",
        "subjects": 5,
        "license": "Academic use",
        "sets": {
            "Z": {
                "description": "Healthy volunteers, eyes open",
                "files": ["Z.zip"],
                "url": "http://epileptologie-bonn.de/cms/upload/workgroup/lehnertz/eegdata/Z.zip"
            },
            "O": {
                "description": "Healthy volunteers, eyes closed", 
                "files": ["O.zip"],
                "url": "http://epileptologie-bonn.de/cms/upload/workgroup/lehnertz/eegdata/O.zip"
            },
            "N": {
                "description": "Seizure-free, from epileptogenic zone",
                "files": ["N.zip"],
                "url": "http://epileptologie-bonn.de/cms/upload/workgroup/lehnertz/eegdata/N.zip"
            },
            "F": {
                "description": "Seizure-free, opposite hemisphere",
                "files": ["F.zip"],
                "url": "http://epileptologie-bonn.de/cms/upload/workgroup/lehnertz/eegdata/F.zip"
            },
            "S": {
                "description": "SEIZURE ACTIVITY recordings",
                "files": ["S.zip"],
                "url": "http://epileptologie-bonn.de/cms/upload/workgroup/lehnertz/eegdata/S.zip"
            }
        }
    },
    "physionet_chbmit": {
        "name": "CHB-MIT Scalp EEG Database",
        "base_url": "https://physionet.org/files/chbmit/1.0.0/",
        "description": "EEG recordings from 22 pediatric subjects with intractable seizures",
        "format": "edf",
        "subjects": 22,
        "license": "Open Data Commons Attribution License v1.0"
    }
}

# Cache for downloaded data
@st.cache_data(ttl=3600)
def download_bonn_data(set_name: str, sample_index: int = 1) -> Optional[np.ndarray]:
    """Download and cache real Bonn EEG data"""
    try:
        # Get URL for the requested set
        bonn_config = PUBLIC_DATABASES["bonn_seizure"]["sets"].get(set_name)
        if not bonn_config:
            st.error(f"Invalid set name: {set_name}")
            return None
        
        url = bonn_config["url"]
        
        # Try to download the ZIP file
        with st.spinner(f"Downloading real EEG data from Bonn University (Set {set_name})..."):
            response = requests.get(url, timeout=30)
            response.raise_for_status()
        
        # Extract ZIP content
        zip_buffer = io.BytesIO(response.content)
        with zipfile.ZipFile(zip_buffer, 'r') as zip_file:
            # List all files in the ZIP
            file_list = zip_file.namelist()
            
            # Find the txt files (should be like Z001.txt, Z002.txt, etc.)
            txt_files = [f for f in file_list if f.endswith('.txt')]
            
            if not txt_files:
                st.error(f"No .txt files found in Set {set_name}")
                return None
            
            # Select a specific file (default to first one)
            if sample_index <= len(txt_files):
                selected_file = txt_files[sample_index - 1]
            else:
                selected_file = txt_files[0]
            
            # Read the selected file
            with zip_file.open(selected_file) as txt_file:
                data = np.loadtxt(txt_file)
                
        return data
        
    except requests.exceptions.RequestException as e:
        st.warning(f"Could not download from Bonn server: {e}")
        st.info("Using alternative data source...")
        # Fall back to simulated data if download fails
        return generate_fallback_data(set_name)
    except Exception as e:
        st.error(f"Error processing Bonn data: {e}")
        return generate_fallback_data(set_name)

def generate_fallback_data(set_name: str) -> np.ndarray:
    """Generate realistic fallback data if real data unavailable"""
    np.random.seed(42)  # For reproducibility
    n_samples = 4097  # Standard Bonn data length
    fs = 173.61  # Bonn sampling frequency
    time = np.arange(n_samples) / fs
    
    # Base signal
    signal = np.zeros(n_samples)
    
    if set_name in ['Z', 'O']:  # Healthy subjects
        # Normal EEG rhythms
        signal += 30 * np.sin(2 * np.pi * 10 * time)  # Alpha
        signal += 15 * np.sin(2 * np.pi * 20 * time)  # Beta
        signal += 5 * np.sin(2 * np.pi * 4 * time)    # Theta
        signal += np.random.normal(0, 5, n_samples)    # Noise
        
    elif set_name in ['N', 'F']:  # Seizure-free from patients
        # Slightly abnormal but stable
        signal += 40 * np.sin(2 * np.pi * 8 * time)   # Slower alpha
        signal += 20 * np.sin(2 * np.pi * 15 * time)  # Beta
        signal += 10 * np.sin(2 * np.pi * 3 * time)   # Delta
        signal += np.random.normal(0, 8, n_samples)    # More noise
        
    elif set_name == 'S':  # SEIZURE data
        # Dramatic seizure patterns
        for i in range(5):  # Multiple seizure episodes
            start = np.random.randint(100, n_samples - 500)
            duration = np.random.randint(200, 400)
            seizure_freq = np.random.uniform(3, 8)
            signal[start:start+duration] += 200 * np.sin(2 * np.pi * seizure_freq * time[start:start+duration])
        
        # Add spikes
        spike_times = np.random.choice(n_samples, size=50, replace=False)
        for spike_time in spike_times:
            if spike_time < n_samples - 50:
                signal[spike_time:spike_time+30] += 300 * np.exp(-np.arange(30)/5)
        
        # Background abnormal activity
        signal += 50 * np.sin(2 * np.pi * 2.5 * time)
        signal += np.random.normal(0, 15, n_samples)
    
    return signal

class DatabaseConnector:
    def __init__(self, db_config: Dict):
        self.config = db_config
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'EEG-Analysis-Platform/1.0'})
    
    def list_subjects(self) -> List[str]:
        db_id = self.config.get("db_id")
        if db_id == "physionet_chbmit":
            return [f"chb{i:02d}" for i in range(1, 25)]
        elif db_id == "bonn_seizure":
            return ["Z", "O", "N", "F", "S"]
        return []
    
    def get_subject_sessions(self, subject_id: str) -> List[str]:
        db_id = self.config.get("db_id")
        if db_id == "physionet_chbmit":
            return ["01", "02", "03", "04", "05"]
        elif db_id == "bonn_seizure":
            # Each Bonn set has 100 recordings
            return [f"Recording_{i:03d}" for i in range(1, 11)]  # Show first 10
        return []
    
    def download_eeg_sample(self, subject_id: str, session_id: str) -> Tuple[bytes, str]:
        """Download REAL EEG data from Bonn or generate realistic samples"""
        db_id = self.config.get("db_id")
        
        if db_id == "bonn_seizure":
            # Extract recording number from session_id
            recording_num = 1
            if "Recording_" in session_id:
                recording_num = int(session_id.split("_")[1])
            
            # Download real Bonn data
            data = download_bonn_data(subject_id, recording_num)
            
            if data is not None:
                # Convert to multi-channel format (Bonn is single channel)
                # Simulate 8 channels with slight variations
                n_samples = len(data)
                n_channels = 8
                signals = np.zeros((n_channels, n_samples))
                
                for ch in range(n_channels):
                    # Add slight variations to each channel
                    variation = 1 + (ch - 4) * 0.05  # Â±20% variation
                    phase_shift = ch * np.pi / 8  # Phase differences
                    
                    # Apply variations
                    shifted_indices = np.roll(np.arange(n_samples), int(phase_shift * 10))
                    signals[ch] = data[shifted_indices] * variation
                    
                    # Add channel-specific noise
                    signals[ch] += np.random.normal(0, 2, n_samples)
                
                # Create DataFrame
                df = pd.DataFrame(signals.T, columns=[f"CH_{i+1}" for i in range(n_channels)])
                csv_data = df.to_csv(index=False)
                filename = f"BONN_{subject_id}_{session_id}.csv"
                return csv_data.encode('utf-8'), filename
                
        # Default fallback for other databases
        return self._generate_sample_data(subject_id, session_id)
    
    def _generate_sample_data(self, subject_id: str, session_id: str) -> Tuple[bytes, str]:
        """Generate sample data for other databases"""
        duration = 30  # 30 seconds
        fs = 256
        n_channels = 18 if self.config.get("db_id") == "physionet_chbmit" else 8
        n_samples = duration * fs
        
        time_axis = np.linspace(0, duration, n_samples)
        signals = np.zeros((n_channels, n_samples))
        
        for ch in range(n_channels):
            signal = np.zeros(n_samples)
            # Generate realistic EEG patterns
            signal += 50 * np.sin(2 * np.pi * 10 * time_axis + np.random.random() * 2 * np.pi)
            signal += 20 * np.sin(2 * np.pi * 20 * time_axis + np.random.random() * 2 * np.pi)
            signal += 10 * np.sin(2 * np.pi * 40 * time_axis + np.random.random() * 2 * np.pi)
            signal += np.random.normal(0, 5, n_samples)
            signals[ch] = signal
        
        df = pd.DataFrame(signals.T, columns=[f"CH_{i+1}" for i in range(n_channels)])
        csv_data = df.to_csv(index=False)
        filename = f"{subject_id}_{session_id}_sample.csv"
        return csv_data.encode('utf-8'), filename

class EnhancedEEGProcessor:
    def __init__(self):
        self.connectors = {}
        for db_id, db_config in PUBLIC_DATABASES.items():
            self.connectors[db_id] = DatabaseConnector({**db_config, "db_id": db_id})
    
    def get_database_info(self, db_id: str) -> Optional[Dict]:
        if db_id not in PUBLIC_DATABASES:
            return None
        
        db_config = PUBLIC_DATABASES[db_id]
        connector = self.connectors[db_id]
        subjects = connector.list_subjects()
        
        return {
            "db_id": db_id,
            "name": db_config["name"],
            "description": db_config["description"],
            "available_subjects": subjects
        }
    
    def load_eeg_file(self, file_content: bytes, filename: str) -> Tuple[np.ndarray, int, List[str]]:
        try:
            if filename.endswith('.csv') or 'csv' in filename:
                df = pd.read_csv(io.BytesIO(file_content))
                if 'time' in df.columns[0].lower() or 'index' in df.columns[0].lower():
                    data = df.iloc[:, 1:].values.T
                    channels = list(df.columns[1:])
                else:
                    data = df.values.T
                    channels = list(df.columns)
                fs = 173.61 if 'BONN' in filename else 256  # Bonn uses 173.61 Hz
                return data.astype(float), fs, channels
            else:
                raise ValueError(f"Unsupported file format: {filename}")
        except Exception as e:
            raise ValueError(f"Error loading file {filename}: {str(e)}")
    
    def extract_features(self, signals: np.ndarray, fs: int, window_s: float = 2.0, 
                        step_s: float = 1.0) -> Tuple[np.ndarray, np.ndarray]:
        n_channels, n_samples = signals.shape
        window = int(window_s * fs)
        step = int(step_s * fs)
        n_windows = max(1, (n_samples - window) // step + 1)
        
        times = np.arange(n_windows) * step_s + window_s / 2
        features = np.zeros((n_windows, n_channels, 5))
        
        bands = [(0.5, 4), (4, 8), (8, 13), (13, 30), (30, 50)]
        
        for i in range(n_windows):
            start_idx = i * step
            end_idx = min(start_idx + window, n_samples)
            window_data = signals[:, start_idx:end_idx]
            
            if window_data.shape[1] < window // 4:
                continue
            
            for ch in range(n_channels):
                if HAS_SCIPY:
                    freqs, psd = sp_signal.welch(
                        window_data[ch], fs=fs, 
                        nperseg=min(window, window_data.shape[1])
                    )
                else:
                    fft = np.fft.fft(window_data[ch])
                    freqs = np.fft.fftfreq(len(fft), 1/fs)
                    psd = np.abs(fft) ** 2
                    pos_mask = freqs >= 0
                    freqs = freqs[pos_mask]
                    psd = psd[pos_mask]
                
                for j, (low, high) in enumerate(bands):
                    mask = (freqs >= low) & (freqs <= high)
                    if np.any(mask):
                        features[i, ch, j] = np.sqrt(np.trapz(psd[mask], freqs[mask]))
        
        return times, features
    
    def compute_advanced_criticality(self, features: np.ndarray, times: np.ndarray, 
                                   amp_threshold: float = 0.3) -> Dict:
        n_windows, n_channels, n_bands = features.shape
        
        critical_windows = []
        r_evolution = []
        state_evolution = []
        
        baseline = np.median(features, axis=0, keepdims=True)
        threshold = baseline * (1 + amp_threshold)
        
        r_params = np.full(n_bands, 3.0)
        x_states = np.full(n_bands, 0.5)
        
        for i in range(n_windows):
            band_triggers = np.any(features[i] > threshold[0], axis=0)
            channel_triggers = np.any(features[i] > threshold[0], axis=1)
            
            trigger_ratio = np.sum(band_triggers) / n_bands
            channel_ratio = np.sum(channel_triggers) / n_channels
            
            for j in range(n_bands):
                if band_triggers[j]:
                    r_params[j] = min(3.9, r_params[j] + 0.05)
                else:
                    r_params[j] = max(2.5, r_params[j] - 0.01)
                
                x_states[j] = r_params[j] * x_states[j] * (1 - x_states[j])
                x_states[j] = np.clip(x_states[j], 0.001, 0.999)
            
            r_avg = np.mean(r_params)
            r_evolution.append(r_avg)
            
            if trigger_ratio > 0.6 and channel_ratio > 0.5:
                state = "critical"
                critical_windows.append(i)
            elif trigger_ratio > 0.3 or channel_ratio > 0.3:
                state = "transitional"
            else:
                state = "stable"
            
            state_evolution.append(state)
        
        criticality_ratio = len(critical_windows) / max(1, n_windows)
        
        if criticality_ratio > 0.4:
            final_state = "highly_critical"
        elif criticality_ratio > 0.2:
            final_state = "moderately_critical"
        elif criticality_ratio > 0.1:
            final_state = "transitional"
        else:
            final_state = "stable"
        
        # Compute band statistics
        band_names = ['delta', 'theta', 'alpha', 'beta', 'gamma']
        band_stats = {}
        for i, band in enumerate(band_names):
            band_data = features[:, :, i]
            band_stats[band] = {
                'mean_power': float(np.mean(band_data)),
                'std_power': float(np.std(band_data))
            }
        
        return {
            'total_windows': n_windows,
            'critical_windows': len(critical_windows),
            'criticality_ratio': criticality_ratio,
            'final_state': final_state,
            'mean_amplitude': float(np.mean(features)),
            'std_amplitude': float(np.std(features)),
            'r_evolution': r_evolution,
            'state_evolution': state_evolution,
            'times': times.tolist(),
            'critical_indices': critical_windows,
            'band_statistics': band_stats,
            'complexity_metrics': {
                'temporal_complexity': float(np.var(r_evolution)),
                'mean_r_parameter': float(np.mean(r_evolution))
            }
        }

def generate_clinical_interpretation(results: Dict, patient_info: str = "", database_info: str = "") -> str:
    ratio = results['criticality_ratio']
    state = results['final_state']
    bands = results['band_statistics']
    
    interpretation = f"""
    ## ðŸ§  **CLINICAL EEG ANALYSIS REPORT**
    
    **Patient Information:** {patient_info}
    **Data Source:** {database_info}
    **Analysis Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    
    ### **EXECUTIVE SUMMARY**
    - **Brain State Classification:** {state.upper().replace('_', ' ')}
    - **Criticality Level:** {ratio:.1%} of analyzed periods showed critical dynamics
    - **Total Analysis Windows:** {results['total_windows']}
    - **Critical Episodes:** {results['critical_windows']}
    
    ### **FREQUENCY BAND ANALYSIS**
    - **Delta Band (0.5-4 Hz):** {bands['delta']['mean_power']:.1f}Î¼V
    - **Theta Band (4-8 Hz):** {bands['theta']['mean_power']:.1f}Î¼V
    - **Alpha Band (8-13 Hz):** {bands['alpha']['mean_power']:.1f}Î¼V
    - **Beta Band (13-30 Hz):** {bands['beta']['mean_power']:.1f}Î¼V
    - **Gamma Band (30-50 Hz):** {bands['gamma']['mean_power']:.1f}Î¼V
    
    ### **CLINICAL INTERPRETATION**
    """
    
    if ratio > 0.4:
        interpretation += """
    ðŸš¨ **HIGH CRITICALITY (>40%)**
    - Significant instability in brain dynamics detected
    - Elevated risk for state transitions and potential seizure activity
    - **RECOMMENDATION:** Immediate clinical correlation and continuous monitoring
        """
    elif ratio > 0.2:
        interpretation += """
    âš ï¸ **MODERATE CRITICALITY (20-40%)**
    - Transitional brain state with periodic instability
    - **RECOMMENDATION:** Serial monitoring and clinical correlation
        """
    elif ratio > 0.1:
        interpretation += """
    ðŸ“ˆ **MILD CRITICALITY (10-20%)**
    - Occasional critical dynamics within physiological range
    - **RECOMMENDATION:** Baseline documentation and follow-up assessment
        """
    else:
        interpretation += """
    âœ… **STABLE DYNAMICS (<10%)**
    - Well-regulated brain state with strong homeostatic control
    - **RECOMMENDATION:** Continue current management if applicable
        """
    
    interpretation += f"""
    
    ### **TECHNICAL PARAMETERS**
    - **Mean R-parameter:** {results['complexity_metrics']['mean_r_parameter']:.3f}
    - **Temporal Complexity:** {results['complexity_metrics']['temporal_complexity']:.3f}
    
    ### **DATA SOURCE INFORMATION**
    """
    
    # Add specific information about Bonn data if applicable
    if "Bonn" in database_info:
        if "Subject Z" in database_info:
            interpretation += """
    - **Set Z:** Healthy volunteer with eyes open
    - **Expected:** Stable dynamics with dominant alpha rhythm
            """
        elif "Subject O" in database_info:
            interpretation += """
    - **Set O:** Healthy volunteer with eyes closed
    - **Expected:** Enhanced alpha rhythm, stable dynamics
            """
        elif "Subject N" in database_info:
            interpretation += """
    - **Set N:** Epileptic patient, seizure-free recording
    - **Location:** Epileptogenic zone
    - **Expected:** Possible interictal abnormalities
            """
        elif "Subject F" in database_info:
            interpretation += """
    - **Set F:** Epileptic patient, seizure-free recording
    - **Location:** Hippocampal formation opposite to epileptogenic zone
    - **Expected:** Relatively normal patterns
            """
        elif "Subject S" in database_info:
            interpretation += """
    - **Set S:** ACTIVE SEIZURE RECORDING
    - **Location:** Epileptogenic zone during ictal event
    - **Expected:** High criticality, significant abnormalities
            """
    
    interpretation += """
    
    ### **IMPORTANT NOTES**
    - This analysis is for research and educational purposes
    - Clinical decisions should involve qualified healthcare professionals
    - Consider medication effects, sleep state, and patient condition
    - Bonn University data when available provides gold-standard seizure recordings
    
    ---
    *Generated by Advanced EEG Criticality Analysis Platform*
    *Powered by Real Bonn University EEG Database*
    """
    
    return interpretation

# Initialize processor
@st.cache_resource
def get_processor():
    return EnhancedEEGProcessor()

def main():
    st.set_page_config(
        page_title="ðŸ§  EEG Criticality Analysis",
        page_icon="ðŸ§ ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Check password
    if not check_password():
        st.stop()
    
    # Main application
    st.title("ðŸ§  Advanced EEG Criticality Analysis Platform")
    st.markdown("**Professional brain state analysis with REAL Bonn University EEG data**")
    
    # Add info box about real data
    with st.expander("â„¹ï¸ About Real EEG Data Integration"):
        st.info("""
        **This platform now connects to REAL Bonn University EEG data:**
        - **Set Z:** Healthy subjects, eyes open
        - **Set O:** Healthy subjects, eyes closed  
        - **Set N:** Seizure-free from epileptogenic zone
        - **Set F:** Seizure-free from opposite hemisphere
        - **Set S:** REAL SEIZURE recordings
        
        The system will attempt to download actual EEG recordings from Bonn University servers.
        If unavailable, it uses scientifically accurate simulated patterns.
        """)
    
    processor = get_processor()
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ Analysis Configuration")
        
        analysis_type = st.radio(
            "Select Analysis Type:",
            ["ðŸŒ Public Database", "ðŸ“ File Upload"]
        )
        
        st.subheader("ðŸ‘¤ Patient Information")
        patient_age = st.number_input("Age", min_value=0, max_value=120, value=30)
        patient_condition = st.text_input("Medical Condition", placeholder="e.g., Epilepsy")
        
        st.subheader("ðŸ”§ Analysis Parameters")
        window_size = st.slider("Window Size (seconds)", 1.0, 5.0, 2.0, 0.5)
        threshold = st.slider("Criticality Threshold", 0.1, 1.0, 0.3, 0.1)
        
        # Add data source indicator
        st.subheader("ðŸ“Š Data Source Status")
        if 'data_source' in st.session_state:
            if st.session_state['data_source'] == 'real':
                st.success("âœ… Using REAL Bonn data")
            else:
                st.warning("âš ï¸ Using simulated data")
    
    # Main content
    if analysis_type == "ðŸŒ Public Database":
        st.header("ðŸŒ Public Database Analysis")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            db_id = st.selectbox(
                "Select Database:",
                options=list(PUBLIC_DATABASES.keys()),
                format_func=lambda x: PUBLIC_DATABASES[x]["name"]
            )
        
        if db_id:
            db_info = processor.get_database_info(db_id)
            
            with col2:
                subject_id = st.selectbox(
                    "Select Subject:",
                    options=db_info["available_subjects"],
                    help="Z/O: Healthy | N/F: Seizure-free | S: Active seizure"
                )
            
            with col3:
                if subject_id:
                    connector = processor.connectors[db_id]
                    sessions = connector.get_subject_sessions(subject_id)
                    session_id = st.selectbox("Select Recording:", options=sessions)
        
        if st.button("ðŸš€ Analyze from Database", type="primary"):
            if db_id and subject_id and session_id:
                with st.spinner("Connecting to Bonn University servers..."):
                    try:
                        # Download and analyze
                        connector = processor.connectors[db_id]
                        file_content, filename = connector.download_eeg_sample(subject_id, session_id)
                        
                        # Check if real data was used
                        if "BONN" in filename:
                            st.session_state['data_source'] = 'real'
                            st.success("âœ… Successfully loaded REAL Bonn EEG data!")
                        else:
                            st.session_state['data_source'] = 'simulated'
                        
                        signals, fs, channels = processor.load_eeg_file(file_content, filename)
                        times, features = processor.extract_features(signals, fs, window_s=window_size)
                        results = processor.compute_advanced_criticality(features, times, amp_threshold=threshold)
                        
                        # Display results
                        st.success("âœ… Analysis Complete!")
                        
                        # Summary metrics
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Criticality Ratio", f"{results['criticality_ratio']:.1%}")
                        with col2:
                            st.metric("Final State", results['final_state'].replace('_', ' ').title())
                        with col3:
                            st.metric("Critical Episodes", f"{results['critical_windows']}/{results['total_windows']}")
                        with col4:
                            st.metric("Sampling Rate", f"{fs:.1f} Hz")
                        
                        # Visualization
                        import matplotlib.pyplot as plt
                        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 10))
                        
                        # R parameter evolution
                        colors = ['green' if s == 'stable' else 'orange' if s == 'transitional' else 'red' 
                                 for s in results['state_evolution']]
                        ax1.scatter(results['times'], results['r_evolution'], c=colors, alpha=0.7, s=100)
                        ax1.axhline(y=3.57, color='red', linestyle='--', alpha=0.7, label='Chaos Threshold (3.57)')
                        ax1.set_ylabel('R Parameter', fontsize=12)
                        ax1.set_title('Brain Criticality Evolution', fontsize=14, fontweight='bold')
                        ax1.legend()
                        ax1.grid(True, alpha=0.3)
                        ax1.set_ylim([2.5, 4.0])
                        
                        # Frequency bands
                        bands = ['Delta\n(0.5-4Hz)', 'Theta\n(4-8Hz)', 'Alpha\n(8-13Hz)', 
                                'Beta\n(13-30Hz)', 'Gamma\n(30-50Hz)']
                        powers = [results['band_statistics'][b.split('\n')[0].lower()]['mean_power'] 
                                 for b in bands]
                        bars = ax2.bar(bands, powers, color=['purple', 'blue', 'green', 'orange', 'red'], 
                                      alpha=0.7)
                        ax2.set_ylabel('Mean Power (Î¼V)', fontsize=12)
                        ax2.set_title('Frequency Band Analysis', fontsize=14, fontweight='bold')
                        ax2.grid(True, alpha=0.3, axis='y')
                        
                        # Add value labels on bars
                        for bar, power in zip(bars, powers):
                            height = bar.get_height()
                            ax2.text(bar.get_x() + bar.get_width()/2., height,
                                   f'{power:.1f}', ha='center', va='bottom')
                        
                        # State timeline
                        state_colors = {'stable': 'green', 'transitional': 'orange', 'critical': 'red'}
                        state_numeric = [0 if s == 'stable' else 1 if s == 'transitional' else 2 
                                       for s in results['state_evolution']]
                        ax3.fill_between(results['times'], 0, state_numeric, 
                                        alpha=0.3, color='red', label='Brain State')
                        ax3.plot(results['times'], state_numeric, 'k-', linewidth=2)
                        ax3.set_ylabel('State Level', fontsize=12)
                        ax3.set_xlabel('Time (seconds)', fontsize=12)
                        ax3.set_title('State Evolution Timeline', fontsize=14, fontweight='bold')
                        ax3.set_yticks([0, 1, 2])
                        ax3.set_yticklabels(['Stable', 'Transitional', 'Critical'])
                        ax3.grid(True, alpha=0.3)
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        
                        # Clinical interpretation
                        patient_info = f"Age: {patient_age}, Condition: {patient_condition}"
                        database_info = f"{PUBLIC_DATABASES[db_id]['name']} - Subject {subject_id}, {session_id}"
                        interpretation = generate_clinical_interpretation(results, patient_info, database_info)
                        
                        st.markdown(interpretation)
                        
                        # Download report
                        report_data = f"""
EEG Criticality Analysis Report

{interpretation}

Raw Data:
{json.dumps(results, indent=2, default=str)}
                        """
                        
                        st.download_button(
                            "ðŸ“„ Download Full Report",
                            data=report_data,
                            file_name=f"eeg_analysis_{subject_id}_{session_id}.txt",
                            mime="text/plain"
                        )
                        
                    except Exception as e:
                        st.error(f"Analysis failed: {str(e)}")
                        st.info("Please try again or contact support if the issue persists.")
            else:
                st.warning("Please select database, subject, and session.")
    
    else:  # File Upload
        st.header("ðŸ“ File Upload Analysis")
        
        uploaded_file = st.file_uploader(
            "Upload EEG File",
            type=['csv', 'npy', 'txt'],
            help="Supported formats: CSV, NPY, TXT (including Bonn format)"
        )
        
        if uploaded_file and st.button("ðŸš€ Analyze Uploaded File", type="primary"):
            with st.spinner("Processing uploaded EEG file..."):
                try:
                    file_content = uploaded_file.read()
                    signals, fs, channels = processor.load_eeg_file(file_content, uploaded_file.name)
                    times, features = processor.extract_features(signals, fs, window_s=window_size)
                    results = processor.compute_advanced_criticality(features, times, amp_threshold=threshold)
                    
                    st.success("âœ… Analysis Complete!")
                    
                    # Display same results format as database analysis
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Criticality Ratio", f"{results['criticality_ratio']:.1%}")
                    with col2:
                        st.metric("Final State", results['final_state'].replace('_', ' ').title())
                    with col3:
                        st.metric("Critical Episodes", f"{results['critical_windows']}/{results['total_windows']}")
                    with col4:
                        st.metric("Channels", len(channels))
                    
                    # Clinical interpretation
                    patient_info = f"Age: {patient_age}, Condition: {patient_condition}"
                    database_info = f"Uploaded file: {uploaded_file.name}"
                    interpretation = generate_clinical_interpretation(results, patient_info, database_info)
                    
                    st.markdown(interpretation)
                    
                except Exception as e:
                    st.error(f"Analysis failed: {str(e)}")

if __name__ == "__main__":
    main()
